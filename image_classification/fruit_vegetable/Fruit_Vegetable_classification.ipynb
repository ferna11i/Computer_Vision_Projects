{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fruit_Vegetable_classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1L2HunWu25IwAtGSMlcjBVtx5WQFgDQdy","authorship_tag":"ABX9TyOMwnR6BcUg/XhLd5zKCZ1r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uXaGLZNzgcdG"},"source":["# Code to split the training data\n","\n","It is easier to zip the content and upload it onto google drive instead of directly uploading the images."]},{"cell_type":"code","metadata":{"id":"gD3zN2xSIYaw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631650159197,"user_tz":240,"elapsed":123,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}},"outputId":"dc3bf258-ff34-4d0a-a50a-4ce7bbbf012d"},"source":["%cd '/content/drive/MyDrive/data/fruits_360'"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/data/fruits_360\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eANX-c7Kj12B","executionInfo":{"status":"ok","timestamp":1631650168265,"user_tz":240,"elapsed":307,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}},"outputId":"d5362cf2-0ebe-4fb6-9dfa-d862586ecae3"},"source":["%ls -l"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["total 412667\n","drwx------   2 root root      4096 Sep 11 20:33 \u001b[0m\u001b[01;34mTest\u001b[0m/\n","-rw-------   1 root root 102891327 Sep 11 16:12 Test.zip\n","drwx------ 129 root root      4096 Sep 11 16:09 \u001b[01;34mTraining\u001b[0m/\n","-rw-------   1 root root   5202043 Sep 11 20:33 Training.csv\n","-rw-------   1 root root 313167483 Sep 11 16:04 Training.zip\n","-rw-------   1 root root   1300178 Sep 11 20:33 Validation.csv\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPqBkipAKARl","executionInfo":{"status":"ok","timestamp":1631650174938,"user_tz":240,"elapsed":151,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}},"outputId":"2f98274d-16ff-47e5-ecfe-a0eb44ceeb00"},"source":["# !unzip Test.zip\n","src = '/content/drive/MyDrive/data/fruits_360'\n","import os\n","\n","filenames = os.listdir(src + \"/Test\")\n","len(filenames)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["96"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"Zzh_reFNiZAA","executionInfo":{"status":"ok","timestamp":1631650188854,"user_tz":240,"elapsed":143,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["import os\n","import pandas as pd\n","\n","main_dir = '/content/drive/MyDrive/data/fruits_360/'\n","model_dir = '/content/drive/MyDrive/models/'"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLLUzPeeihxW","executionInfo":{"status":"ok","timestamp":1631650247240,"user_tz":240,"elapsed":56165,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["#This piece of code was used to extract the class names for the image\n","#Would just need to split the refer to the correct folder to generate the right\n","#type of data. Example change field data_type to 'Train'\n","\n","data_type = 'Test'\n","df = pd.DataFrame(columns=[\"filename\", \"filepath\",\"class_name\", \"class\"])\n","folder_names = os.listdir(main_dir + data_type)\n","\n","class_names = []\n","idx = -1\n","for folder_name in folder_names:\n","  class_name = folder_name.replace(\" \",\"_\")\n","  filenames = os.listdir(main_dir + data_type + \"/\" + folder_name)\n","\n","  if class_name not in class_names:\n","    class_names.append(class_name)\n","    idx += 1\n","\n","  for filename in filenames:\n","    row = [filename, \n","           main_dir + data_type + \"/\" + folder_name + \"/\" + filename,\n","           class_name,\n","           idx]\n","\n","    df.loc[len(df)] = row"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhSJDkT82m_p"},"source":["#For training and validation data\n","\n","#Shuffle the training dataset\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","#Split the training dataset into train and validation\n","train_df = df[:52208]\n","val_df = df[52208:]\n","\n","train_df.to_csv(main_dir + \"Training.csv\", index=False)\n","val_df.to_csv(main_dir + \"Validation.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ryy7HCufk2tW","executionInfo":{"status":"ok","timestamp":1631650318396,"user_tz":240,"elapsed":123,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["#For testing data\n","df.to_csv(main_dir + \"Test.csv\", index=False)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6iQ8TQtyledm"},"source":["# Setting the model architecture "]},{"cell_type":"code","metadata":{"id":"9NAw0Uw1lSKe","executionInfo":{"status":"ok","timestamp":1631632886690,"user_tz":240,"elapsed":2962,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["#Hacked version of resnet with Gropu Normalization \n","#Will need to rework this to a better solution\n","import sys\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from torch.utils.data import Dataset, DataLoader\n","import pickle\n","import time\n","from PIL import Image\n","from sklearn.metrics import recall_score, precision_score\n","import pandas as pd\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","main_dir = '/content/drive/MyDrive/data/fruits_360/'\n","model_dir = '/content/drive/MyDrive/models/'\n","\n","# sys.path.append('/content/drive/My Drive/models')\n","# from resnet import resnet50"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ysmu56T5lUJl","executionInfo":{"status":"ok","timestamp":1631658394053,"user_tz":240,"elapsed":729,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["net = models.resnet50()\n","# net.load_state_dict(torch.load(model_dir + \"resnet50.pth\"))\n","\n","in_features = net.fc.in_features\n","net.fc = nn.Linear(in_features, 131)\n","\n","net.load_state_dict(torch.load(model_dir + 'res50_fruit_ep2.pth' ))\n","\n","ce_loss = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n","\n","net = net.to(device)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wlGrfvB7Ay6"},"source":["# for name, parameters in net.named_parameters():\n","#   print(name + \" \" + str(parameters.requires_grad))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KTR7h8Kkns0n"},"source":["# Set the Dataset and Dataloaders"]},{"cell_type":"code","metadata":{"id":"orsqU7tUnxnY","executionInfo":{"status":"ok","timestamp":1631632935163,"user_tz":240,"elapsed":149,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["\n","class FruitDataset(Dataset):\n","\n","    def __init__(self, csv_file, root_dir, transforms=None):\n","        self.root_dir = root_dir\n","        self.csv_file = pd.read_csv(main_dir + csv_file)\n","        self.transforms = transforms\n","        self.c = 131\n","\n","    def __len__(self):\n","        return len(self.csv_file)\n","\n","    def __getitem__(self, idx):\n","        image_det = self.csv_file.iloc[idx]\n","        image = Image.open(image_det['filepath'])\n","        label = torch.tensor(image_det['class'])\n","\n","        if self.transforms:\n","            image = self.transforms(image)\n","\n","        return image, label\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTtDynQ_oE4t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631650336359,"user_tz":240,"elapsed":297,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}},"outputId":"90c7ccc5-7476-44c7-b0e0-f8748474ee21"},"source":["train_data_transforms = transforms.Compose([ transforms.Resize((224, 224)),\n","                                              transforms.RandomRotation((-30, 30)),\n","                                              transforms.RandomHorizontalFlip(),\n","                                              transforms.ToTensor(),\n","                                              transforms.Normalize(\n","                                                  mean=[0.485, 0.456, 0.406],\n","                                                  std=[0.229, 0.224, 0.225])\n","                                              ])\n","\n","\n","test_data_transforms = transforms.Compose([ transforms.Resize((224, 224)),\n","                                              transforms.ToTensor(),\n","                                              transforms.Normalize(\n","                                                  mean=[0.485, 0.456, 0.406],\n","                                                  std=[0.229, 0.224, 0.225])\n","                                              ])\n","\n","\n","train_data_set = FruitDataset('Training.csv', main_dir, train_data_transforms)\n","val_data_set = FruitDataset('Validation.csv', main_dir, train_data_transforms)\n","test_data_set = FruitDataset('Test.csv', main_dir, test_data_transforms)\n","\n","batch_data_loader = {'Train' : DataLoader(train_data_set, batch_size=128, shuffle=True),\n","                     'Val' : DataLoader(val_data_set, batch_size=32),\n","                     'Test' : DataLoader(val_data_set, batch_size=32)}\n","\n","data_sizes = {'Train' : len(train_data_set), \n","              'Val' : len(val_data_set),\n","              'Test' : len(test_data_set)}\n","\n","print(data_sizes)\n","print(device)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Train': 52208, 'Val': 13050, 'Test': 13695}\n","cuda\n"]}]},{"cell_type":"markdown","metadata":{"id":"kPxiqsWPgTjo"},"source":["# Functions to train, test and provide evaluation results"]},{"cell_type":"code","metadata":{"id":"-XqbKzbLyCWZ","executionInfo":{"status":"ok","timestamp":1631658243969,"user_tz":240,"elapsed":135,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}}},"source":["def evaluate(phase, running_loss, running_corrects, targets, pred_labels):\n","\n","  print(flush=True)\n","\n","  epoch_loss = running_loss / data_sizes[phase]\n","  epoch_accuracy = running_corrects.double() / data_sizes[phase]\n","  recall = recall_score(targets, pred_labels, pos_label=0, average='micro')\n","  precision = precision_score(targets, pred_labels, pos_label=0, average='micro')\n","\n","  print(\"{} Loss :{}, Recall : {}, Precision : {}\"\n","        .format(phase, epoch_loss, recall, precision), flush=True)\n","      \n","\n","\n","#Training loop\n","def train_one_epoch(phase, model, train_dataloader):\n","\n","    running_loss = 0.0\n","    running_corrects = 0.0\n","    pred_labels = []\n","    targets = []\n","\n","    iterations = int(data_sizes[phase] / train_dataloader.batch_size)\n","\n","    for batch_idx, batch_data in enumerate(train_dataloader):\n","\n","        sys.stdout.write('\\r')\n","        sys.stdout.write(\"{} Iteration :{}/{}\"\n","                          .format(phase, batch_idx + 1, iterations))\n","\n","        inputs = batch_data[0]\n","        # Pytorch autograd seems to work only with float labels not int values\n","        labels = batch_data[1]\n","        # labels = labels.type(torch.LongTensor)\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()  # Don't want gradients to accumulate\n","\n","        with torch.set_grad_enabled(phase == 'Train'):\n","            outputs = model(inputs)  # Outputs are probabilities\n","\n","            loss = ce_loss(outputs, labels)  # Calculate loss\n","            y_pred_softmax = torch.log_softmax(outputs, dim=1)\n","            _, pred = torch.max(y_pred_softmax, dim=1)\n","\n","            loss.backward()  # Calculate gradient for trainable each node\n","            optimizer.step()  # Update weights with gradient\n","\n","        # Loss per batch is accumulated\n","        running_loss += loss.item() * inputs.size(0)\n","        #For accuracy\n","        running_corrects += torch.sum(pred == labels)\n","\n","        pred_labels += pred.detach().cpu().numpy().tolist()\n","        targets +=  labels.detach().cpu().numpy().tolist()\n","\n","\n","    # evaluate(running_loss, running_corrects, targets, pred_labels)\n","    return model\n","\n","\n","\n","def test_model(phase, model, dataloader):\n","\n","  running_loss = 0.0\n","  running_corrects = 0.0\n","  pred_labels = []\n","  targets = []\n","\n","  iterations = int(data_sizes[phase] / dataloader.batch_size)\n","\n","  for batch_idx, batch_data in enumerate(dataloader):\n","\n","      sys.stdout.write('\\r')\n","      sys.stdout.write(\"{} Iteration :{}/{}\"\n","                        .format(phase, batch_idx + 1, iterations))\n","\n","\n","      inputs = batch_data[0]\n","      # Pytorch autograd seems to work only with float labels not int values\n","      labels = batch_data[1]\n","      labels = labels.type(torch.LongTensor)\n","\n","      inputs = inputs.to(device)\n","      labels = labels.to(device)\n","          \n","\n","      with torch.set_grad_enabled(phase == 'Train'):\n","          outputs = model(inputs)  # Outputs are probabilities\n","\n","          loss = ce_loss(outputs, labels)  # Calculate loss\n","          y_pred_softmax = torch.log_softmax(outputs, dim=1)\n","          _, pred = torch.max(y_pred_softmax, dim=1)\n","\n","\n","      # Loss per batch is accumulated\n","      running_loss += loss.item() * inputs.size(0)\n","      #For accuracy\n","      running_corrects += torch.sum(pred == labels)\n","\n","      pred_labels += pred.detach().cpu().numpy().tolist()\n","      targets +=  labels.detach().cpu().numpy().tolist()\n","\n","\n","  evaluate(phase, running_loss, running_corrects, targets, pred_labels)\n","\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8ZqDV668f3G","executionInfo":{"status":"ok","timestamp":1631659168360,"user_tz":240,"elapsed":767150,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}},"outputId":"1ff9149e-bae8-4c8d-ed5c-fa74ce370612"},"source":["# Model was trained for three epochs on three days separately.\n","\n","no_epochs = 1\n","\n","for epoch in range(no_epochs):\n","    since = time.time()\n","    print(\"Epoch : {}/{}\".format(epoch + 1, no_epochs), flush=True)\n","\n","    for phase in ['Train', 'Val']:\n","        print(phase + \" begins\")\n","        if phase == 'Train':\n","            net.train()\n","            net = train_one_epoch(phase, net, batch_data_loader[phase])\n","        else:  # For validation\n","            net.eval()\n","            test_model(phase, net, batch_data_loader[phase])\n","\n","\n","    torch.save(net.state_dict(), model_dir + 'res50_fruit_ep3.pth')\n","\n","    time_elapsed = time.time() - since\n","    print(\"Time elapsed in {}\".format(time_elapsed), flush=True)\n","\n","    print(\"-\" * 10)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 1/1\n","Train begins\n","Train Iteration :408/407Val begins\n","Val Iteration :408/407\n","Val Loss :0.020316148123122265, Recall : 1.0, Precision : 1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n","  % (pos_label, average), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Time elapsed in 767.0186641216278\n","----------\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZqtpzk75B3o","executionInfo":{"status":"ok","timestamp":1631659668575,"user_tz":240,"elapsed":76346,"user":{"displayName":"fern1084","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11044789249512877067"}},"outputId":"468fd6ee-02c2-42f5-a867-bfc73d46c36d"},"source":["phase = \"Test\"\n","net.eval()\n","test_model(phase, net, batch_data_loader[phase])"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Iteration :408/427\n","Test Loss :0.019569517374473926, Recall : 0.9999233716475096, Precision : 0.9999233716475096\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n","  % (pos_label, average), UserWarning)\n"]}]}]}